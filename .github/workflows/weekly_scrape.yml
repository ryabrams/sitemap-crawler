name: Weekly Sitemap Scraper

on:
  schedule:
    # Runs at 00:00 on Sunday
    - cron: '0 0 * * 0'
  # Allows you to run this manually from the Actions tab for testing
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scrape-and-commit:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Run Scraper
        run: python scraper.py

      - name: Commit and Push CSV
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          
          # Check if CSV files exist before adding
          if ls CSVs/*.csv 1> /dev/null 2>&1; then
            git add CSVs/*.csv
            # Commit only if there are changes to avoid empty commit errors
            git diff --quiet && git diff --staged --quiet || (git commit -m "Automated: Add sitemap export for $(date +'%Y-%m-%d')" && git push)
            echo "✅ Changes pushed successfully."
          else
            echo "⚠️ No CSV files found. The scraper may have found 0 URLs or encountered an error."
          fi
